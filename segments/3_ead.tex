\begin{frame}{EAD - Tóm lược}
    \begin{itemize}
        \item Hiệu chỉnh elastic-net là công nghệ được sử dụng rộng rãi trong việc giải quyết 
        các bài toán lựa chọn thuộc tính nhiều chiều (Zou and Hastie 2005)

        \item Nhìn chung, hiệu chỉnh elastic-net được sử dụng trong bài toán cực 
        tiểu hóa sau đây:
        \begin{equation}
            \label{eq:3}
            \text{minimize}_{\mathbf{z} \in \mathcal{Z}} \text{ }
            f(\mathbf{z}) + \lambda_1 \lVert \mathbf{z} \rVert_1
            + \lambda_2 \lVert \mathbf{z} \rVert_2^2
        \end{equation}
        Trong đó $\mathbf{z}$ là vector của $p$ biến tối ưu, $\mathcal{Z}$ là tập nghiệm 
        chấp nhận được, $f(\mathbf{z})$ là hàm mất mát, $\lVert \mathbf{z} \rVert_q$ là 
        chuẩn $q$ của $\mathbf{z}$ và $\lambda_1, \lambda_2 \geq 0$ tương ứng là các tham số hiệu 
        chỉnh $L_1$ và $L_2$

        \item Biểu thức $\lambda_1 \lVert \mathbf{z} \rVert_1 + \lambda_2 
        \lVert \mathbf{z} \rVert_2^2$ được gọi là hiệu chỉnh elactic-net của $\mathbf{z}$
    \end{itemize}
\end{frame}

\begin{frame}{EAD - Xây dựng}
    Cho trước 1 ảnh $\mathbf{x_0}$ và nhãn đúng của nó là $t_0$, 
    gọi $\mathbf{x}$ là mẫu đối nghịch của $\mathbf{x_0}$ với lớp đích nhắm đến là $t \neq t_0$ . Hàm mất mát 
    $f(\mathbf{x})$ cho tấn công nhắm đích là:
    \begin{equation}
        \label{eq:4}
        f(\mathbf{x}, t) = \max { \left( \max_{j \neq t} [\textbf{Logit}(\mathbf{x})]_j - 
        [\textbf{Logit}(\mathbf{x})]_t, -\kappa \right) }
    \end{equation}
    Trong đó $\textbf{Logit}(\mathbf{x}) = [\textbf{Logit}(\mathbf{x})_1, ..., 
    \textbf{Logit}(\mathbf{x})_K] 
    \in \mathbb{R}^K$ là lớp logit (lớp trước softmax) biểu diễn cho $\mathbf{x}$ trong mạng DNN, $K$
    là số lượng lớp cần phân loại, $\kappa > 0$ là tham số tin cậy, nó đảm bảo một khoảng 
    cách cố định giữa $\max_{j \neq t} [\textbf{Logit}(\mathbf{x})]_j$ và $[\textbf{Logit}(\mathbf{x})]_t$.
\end{frame}

\begin{frame}{EAD - Xây dựng}
    Thành phần $[\textbf{Logit}(x)]_t$ là xác xuất dự đoán $x$ có nhãn $t$ theo 
    luật phân loại của hàm softmax:
    \begin{equation}
        \label{eq:5}
        \text{Prob}(\text{Label}(\mathbf{x}) = t) = \frac{\exp([\textbf{Logit}(\mathbf{x})]_t)}{
            \sum_{j=1}^{K} \exp([\textbf{Logit}(\mathbf{x})]_j)
        }
    \end{equation}
\end{frame}

\begin{frame}{EAD - Xây dựng}
    Do đó, hàm mất mát trong phương trình (\ref{eq:4}) có mục đích là để cho ra nhãn $t$ là 
    lớp có xác xuất cao nhất của $\mathbf{x}$ và tham số $\kappa$ đảm bảo sự phân biệt giữa lớp $t$
    và lớp dự đoán gần nhất khác với $t$. Với tấn công không nhắm mục tiêu, hàm mất mát trong 
    phương trình \ref{eq:4} trở thành:
    \begin{equation}
        \label{eq:6}\
        f(\mathbf{x}) = \max { \left([\textbf{Logit}(\mathbf{x})]_{t_0} - 
        \max_{j \neq t} [\textbf{Logit}(\mathbf{x})]_j, -\kappa \right) }
    \end{equation}
\end{frame}

\begin{frame}{EAD - Xây dựng}
    Hiệu chỉnh 
    elastic-net còn tạo ra mẫu đối nghịch tương tự với ảnh gốc. Công thức tấn công elastic-net
    vào mạng DNNs (EAD) để tạo ra mẫu đối nghịch $(\mathbf{x},t)$ cho ảnh gốc $(\mathbf{x_0}, t_0)$ như sau:
    \begin{equation}
        \label{eq:7}
        \begin{split}
        &\text{minimize}_{\mathbf{x}} \text{ }
        c \times f(\mathbf{x}, t) + \beta \lVert \mathbf{x} - \mathbf{x_0} \rVert_1
        + \lVert \mathbf{x} - \mathbf{x_0} \rVert_2^2 \\
        &\text{st   } \mathbf{x} \in [0,1]^p
        \end{split}
    \end{equation}
    Với $f(\mathbf{x},t)$ được xác định trong phương trình (\ref{eq:4}), $c, \beta \geq 0$ lần lượt 
    là các tham số  hiệu chỉnh của hàm mất mát $f$ và hàm phạt $L_1$.
\end{frame}

\begin{frame}
    \begin{center}
        \textbf{Thuật toán 1} Tấn công Elastic-net vào DNNs (EAD)
        \begin{itemize}
            \item[] \textbf{Input}: Ảnh gốc và nhãn của nó ($\mathbf{x}_0$, $t_0$), lớp mục tiêu $t$, tham số chuyển giao $\kappa$, tham số hiệu chỉnh $\beta$, độ dài bước $\alpha_k$, số bước lặp $I$
            \item[] \textbf{Output}: mẫu đối nghịch $\mathbf{x}$
            \item[] Khởi tạo: $\mathbf{x}^{(0)}$ = $\mathbf{y}^{(0)}$ = $\mathbf{x}_0$
            \item[] \textbf{for} $k = 0$ to $I - 1$ do
            \begin{itemize}
                \item[] $\mathbf{x}^{(k+1)} = S_{\beta}(\mathbf{y}^{(k)} -\alpha_{k} \nabla g(\mathbf{y}^{(k)}))$
                \item[] $\mathbf{y}^{(k+1)} = \mathbf{x}^{(k+1)} + \frac{k}{k+3} (\mathbf{x}^{(k+1)} - \mathbf{x}^{(k)}) $
            \end{itemize}
            \item[] \textbf{end for}
            \item[] Luật quyết định: tìm $\mathbf{x}$ từ tập các mẫu thành công trong $\{\mathbf{x}^k\}_{k=1}^{I}$ (luật EN, luật $L_1$).
        \end{itemize}
    \end{center}
\end{frame}

\begin{frame}{EAD - Thuật toán}
    Trong đó 
    \begin{equation}
        \label{eq:9}
        [S_{\beta}(\mathbf{z})]_i = 
        \begin{cases}
            \min \{ \mathbf{z}_i - \beta, 1 \} &\text{ nếu } \mathbf{z}_i - \mathbf{x_0}_i  > \beta; \\
            \mathbf{x_0}_i &\text{ nếu } |\mathbf{z}_i - \mathbf{x_0}_i| \leq \beta; \\
            \max \{ \mathbf{z}_i + \beta, 0 \} &\text{ nếu } \mathbf{z}_i - \mathbf{x_0}_i < -\beta
        \end{cases}
    \end{equation}
    Với $i \in \{ 1, ..., p \}$. Nếu $|\mathbf{z}_i - \mathbf{x_0}_i| > \beta$, thành phần 
    $\mathbf{z}_i$ được co lại với hệ số $\beta$ và chiếu thành phần kết quả lên miền ràng buộc 
    chấp nhận được thuộc đoạn $[0,1]$.
\end{frame}